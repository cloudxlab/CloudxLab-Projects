{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3. Custom Loss Function",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WXXmILdwLhl"
      },
      "source": [
        "# Importing the Modules\n",
        "\n",
        "- Let us start by importing the necessary modules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dk64-W0iCA1R"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Njf94h3s_mM9"
      },
      "source": [
        "Let's start by loading and preparing the California housing dataset.\n",
        "\n",
        "We would:\n",
        " \n",
        " - first load the data\n",
        "\n",
        " - then split it into a training set, a validation set, and a test set\n",
        "\n",
        " - finally, we scale it. \n",
        "\n",
        "Note that this dataset contains only numerical features and there are no missing values.\n",
        "\n",
        "**Note:**\n",
        "\n",
        "- For a feature scaler line `StandardScler`, `fit` computes the mean and std(standard deviation) to be used for later scaling (just a computation) based on the given data, nothing is given to you. `transform` uses a previously computed mean and std to autoscale the data (subtract mean from all values and then divide it by std). `fit_transform` does both at the same time.\n",
        "\n",
        "- So, we would be applying the `scaler.fit_transform` on the train data, and just apply `scaler.transform` on the validation and test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QD3zzrZ_gjY"
      },
      "source": [
        "# Use fetch_california_housing() function to load the data. \n",
        "# This dataset contains only numerical features (there is no ocean_proximity feature)\n",
        "# And there is no missing value. \n",
        "# After loading the data, we split it into a training set, a validation set, and a test set\n",
        "# And we scale all the features\n",
        "\n",
        "\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# fetch the data\n",
        "housing = fetch_california_housing()\n",
        "\n",
        "# split it into a training set, a validation set, and a test set\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
        "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X_train_full, y_train_full, random_state=42)\n",
        "\n",
        "# Scale all the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_valid_scaled = scaler.transform(X_valid)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xb0dpU0bG91t",
        "outputId": "e1843a07-f0e9-40a2-d627-4f16184bbdfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(X_test_scaled.min())\n",
        "X_test.min()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-2.33173089548745\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-124.25"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avrDIGp8wjmy"
      },
      "source": [
        "# Defining a Custom Loss Function - Huber Loss\n",
        "\n",
        "Let's implement huber loss. Huber loss is less sensitive to outliers in data than mean squared error. \n",
        "\n",
        "Below is the formula of huber loss.\n",
        "\n",
        "![enter image description here](data:image/png;base64,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)\n",
        "\n",
        "\n",
        "  [1]: https://cxl-web-prod-uploads.s3.amazonaws.com/public/pagedown-uploads/03cb0080a7a3c2d5fbbfabdfab8f4e538131c5cb.png\n",
        "\n",
        "**Note:**\n",
        "\n",
        "- Huber loss is defined as:\n",
        " \n",
        " - *error <sup>2</sup>/2*, if *error < delta*  (ie, if it is a small error)\n",
        "\n",
        " - *delta \\* ( |error| - delta/2)*, otherwise  ( *|error|* means the absolute value *error*)\n",
        "\n",
        "  In this exercise, we consider *delta=1*.\n",
        "\n",
        " Thus, the  `huber_fn`  is defined as:\n",
        "  \n",
        "  - *error <sup>2</sup>/2*, if *error < 1* (ie, if it is a small error).\n",
        "\n",
        " - *|error| - 0.5*, otherwise\n",
        "\n",
        "- `tf.abs(x)` returns the positive value(absolute value) of `x`.\n",
        "\n",
        "- `tf.square(x)` returns the squared value of `x`.\n",
        "\n",
        "- `tf.where(bool_array, x, y)` returns the elements where condition is True in `bool_array` (multiplexing `x` and `y`).\n",
        "\n",
        "  In simpler terms, `tf.where` will choose an output shape from the shapes of condition, `x`, and `y` that all three shapes are broadcastable to.\n",
        "\n",
        " The condition tensor acts as a mask that chooses whether the corresponding element/row in the output should be taken from x (if the element in the condition is `True`) or from `y` (if it is `False`).\n",
        " \n",
        " For example, upon executing the following,\n",
        "\n",
        " `tf.where([True, False, False, True], [1,2,3,4], [100,200,300,400])`\n",
        "\n",
        " the output would be : `<tf.Tensor: shape=(4,), dtype=int32, numpy=array([  1, 200, 300,   4], dtype=int32)>`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8wC1TU6_pgm"
      },
      "source": [
        "# Define a custom loss function\n",
        "# Define Huber loss function\n",
        "\n",
        "def huber_fn(y_true, y_pred):\n",
        "    error = y_true - y_pred\n",
        "    is_small_error = tf.abs(error) < 1\n",
        "    squared_loss = tf.square(error) / 2\n",
        "    linear_loss  = tf.abs(error) - 0.5\n",
        "    return tf.where(is_small_error, squared_loss, linear_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEz03taYNW-E",
        "outputId": "dd3d974c-5e56-49e4-d887-200b5c72c781",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "huber_fn(1.5, 2.5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hX1OiwB_dWK_",
        "outputId": "03d81d8a-3b7d-423d-cbda-7e0148f42fd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tf.where([True, False, False, True], [1,2,3,4], [100,200,300,400])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([  1, 200, 300,   4], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvJbRWlcxX6z"
      },
      "source": [
        "# Building the Network\n",
        "\n",
        "We shall now build the classification network, with a hidden layer(with 30 neurons and `selu` activation function) and an output layer( with 1 neuron since we have to predict only one value).\n",
        "\n",
        "We shall also specify the loss function we have defined - the `huber_fn` and the optimizer to use, while compiling.\n",
        "\n",
        "**Note:**\n",
        "\n",
        "- `kernel_initializer` defines the way to set the initial random weights of Keras layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6SGWjkMB5wK"
      },
      "source": [
        "# Build the network.\n",
        "# Output layer just contains 1 neuron since we have to predict only one value\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
        "                       input_shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(1),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3HlacLXB8Zs"
      },
      "source": [
        "# Specify the loss function and the optimizer to use.\n",
        "# Here we are using custom loss function\n",
        "# Measure MAE during training and evaluation\n",
        "\n",
        "model.compile(loss=huber_fn, optimizer=\"nadam\", metrics=[\"mae\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDV1k3vchfQO",
        "outputId": "eb924256-755d-4211-fa06-f85cc8ae52a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "str(type(model))==\"<class 'tensorflow.python.keras.engine.sequential.Sequential'>\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwge0UwDxhEo"
      },
      "source": [
        "# Training the Model\n",
        "\n",
        "- It's time for training.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_TqiUDjCFvR",
        "outputId": "7f840068-c30e-4926-a3f3-d11bc1f9fbb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(X_train_scaled, y_train, epochs=15,\n",
        "          validation_data=(X_valid_scaled, y_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.6084 - mae: 0.9652 - val_loss: 0.3084 - val_mae: 0.6046\n",
            "Epoch 2/15\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.2187 - mae: 0.5153 - val_loss: 0.2605 - val_mae: 0.5472\n",
            "Epoch 3/15\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.2053 - mae: 0.4964 - val_loss: 0.2199 - val_mae: 0.5018\n",
            "Epoch 4/15\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.1984 - mae: 0.4877 - val_loss: 0.1834 - val_mae: 0.4637\n",
            "Epoch 5/15\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.1936 - mae: 0.4816 - val_loss: 0.2008 - val_mae: 0.4816\n",
            "Epoch 6/15\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.1920 - mae: 0.4785 - val_loss: 0.1901 - val_mae: 0.4731\n",
            "Epoch 7/15\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.1894 - mae: 0.4745 - val_loss: 0.1874 - val_mae: 0.4695\n",
            "Epoch 8/15\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.1870 - mae: 0.4710 - val_loss: 0.1936 - val_mae: 0.4740\n",
            "Epoch 9/15\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.1863 - mae: 0.4693 - val_loss: 0.1821 - val_mae: 0.4635\n",
            "Epoch 10/15\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.1847 - mae: 0.4682 - val_loss: 0.1797 - val_mae: 0.4572\n",
            "Epoch 11/15\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.1828 - mae: 0.4650 - val_loss: 0.1858 - val_mae: 0.4607\n",
            "Epoch 12/15\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.1818 - mae: 0.4624 - val_loss: 0.1749 - val_mae: 0.4511\n",
            "Epoch 13/15\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.1801 - mae: 0.4595 - val_loss: 0.1965 - val_mae: 0.4725\n",
            "Epoch 14/15\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.1791 - mae: 0.4584 - val_loss: 0.1688 - val_mae: 0.4447\n",
            "Epoch 15/15\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.1777 - mae: 0.4559 - val_loss: 0.1904 - val_mae: 0.4644\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb3347e8668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TMrDHCDxlc7"
      },
      "source": [
        "# Evaluating the Model Performance\n",
        "\n",
        "Let us test the model performance by looking at the mae and loss values of the model on test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XU8ANGe0CIQd",
        "outputId": "c9a1ca61-12ee-4f15-a54b-aad7b65b9f0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.evaluate(X_test_scaled, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "162/162 [==============================] - 0s 742us/step - loss: 0.1776 - mae: 0.4575\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1775917261838913, 0.4575499892234802]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Sn5K6L1xqDk"
      },
      "source": [
        "Observe the values of loss and mae. These values are nearly the same as those of the train and validation datasets. Also, the values are low. Hence our model hasn't been overfitted and is giving a decent performance."
      ]
    }
  ]
}