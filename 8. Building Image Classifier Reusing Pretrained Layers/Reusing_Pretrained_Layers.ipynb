{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2. Reusing Pretrained Layers",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONiIGi-AtpIv"
      },
      "source": [
        "# Importing the Modules\n",
        "\n",
        "- Let us begin by importing the necessary modules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVRz9y1yBFzQ"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THIykOdzQNwU",
        "outputId": "f30e7f80-a148-467b-fa59-e7c546cb3dad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "type(keras)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "module"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5LDKxnAtzJl"
      },
      "source": [
        "# Preparing the Dataset\n",
        "\n",
        "- Let us load the dataset and trim it to form a shorter dataset, as training a bigger dataset would take a lot of time.\n",
        "\n",
        "**Note:**\n",
        "\n",
        "- The Fashion MNIST data from `keras` is already preprocessed and already split into train and test sets. So we shall receive them accordingly while loading the data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vasjW4q37FYj"
      },
      "source": [
        "# loading the Fashion-MNIST dataset\n",
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# trimming the data since it takes lot of time\n",
        "X_train_full = X_train_full[:30000]\n",
        "y_train_full = y_train_full[:30000]\n",
        "\n",
        "X_test = X_test[:5000]\n",
        "y_test = y_test[:5000]\n",
        "\n",
        "# scaling the dataset\n",
        "X_train_full = X_train_full / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# dividing the dataset into traingin and validation set\n",
        "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1ZBDCHiTpqB",
        "outputId": "1cdc3145-03a7-416e-e6fa-4803c459f315",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_test.min()==0 and X_test.max()==1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGPzuRbw7bAr"
      },
      "source": [
        "# Dividing the data sets\n",
        "\n",
        "Let's split the fashion MNIST training set in two:\n",
        "\n",
        "**X_train_A:** all images of all items except for sandals and shirts (classes 5 and 6).\n",
        "\n",
        "**X_train_B:** a much smaller training set of just the first 200 images of sandals or shirts.\n",
        "The validation set and the test set are also split this way, but without restricting the number of images.\n",
        "\n",
        "**Why are we doing this?**\n",
        "\n",
        "We will train a model on set A (classification task with 8 classes), and try to reuse it to tackle set B (binary classification). \n",
        "\n",
        "We hope to transfer a little bit of knowledge from task A to task B, since classes in set A (sneakers, ankle boots, coats, t-shirts, etc.) are somewhat similar to classes in set B (sandals and shirts). \n",
        "\n",
        "However, since we are using Dense layers, only patterns that occur at the same location can be reused (in contrast, convolutional layers will transfer much better, since learned patterns can be detected anywhere on the image, as we will see in the CNN chapter)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnXT4j517G0T",
        "outputId": "54ec713f-0cbc-4ad3-a891-80c32a69adbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# defining the dataset\n",
        "def split_dataset(X, y):\n",
        "    y_5_or_6 = (y == 5) | (y == 6) # sandals or shirts\n",
        "    y_A = y[~y_5_or_6]\n",
        "    y_A[y_A > 6] -= 2 # class indices 7, 8, 9 should be moved to 5, 6, 7\n",
        "    y_B = (y[y_5_or_6] == 6).astype(np.float32) # binary classification task: is it a shirt (class 6)?\n",
        "    return ((X[~y_5_or_6], y_A),\n",
        "            (X[y_5_or_6], y_B))\n",
        "\n",
        "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\n",
        "print((X_train_A.shape, y_train_A.shape), (X_train_B.shape, y_train_B.shape))\n",
        "(X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(X_valid, y_valid)\n",
        "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
        "# X_train_B = X_train_B[:200]\n",
        "# y_train_B = y_train_B[:200]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "((19875, 28, 28), (19875,)) ((5125, 28, 28), (5125,))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RvKRfo97ZQ6",
        "outputId": "fb3edb75-beb2-4fe6-9fc2-fc037f24f7fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# checking shape of training set A\n",
        "y_test_A.shape "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4033,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkO7p-lC7mXd",
        "outputId": "5b5a4e99-94c7-4e66-c4c2-46bf7f3bec80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train_B.shape # checking shape of training set B"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5125, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0vUlj907oW5",
        "outputId": "25733164-a672-4add-f25c-ddc2ee94c67e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_train_A[:30] # checking first 30 y-labels for training set A"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 0, 5, 7, 7, 7, 4, 4, 3, 4, 0, 1, 6, 3, 4, 3, 2, 6, 5, 3, 4, 5,\n",
              "       1, 3, 4, 2, 0, 6, 7, 1], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUqk6XpQ7qnz",
        "outputId": "13136e7f-8fc8-4a35-9485-c3af1e432338",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_train_B[:30] # checking first 30 y-labels for training set B"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zw5dHB3I7snk"
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVZJJXGIunrj"
      },
      "source": [
        "# Build and Fit the Model A\n",
        "\n",
        "Let us define the model for the classification of data set A that we have created previously. \n",
        "\n",
        "Later the trained weights of this model will be used for the classification task of data B.\n",
        "\n",
        "- We create a keras neural network as follows:\n",
        "\n",
        " - Add `keras.layers.Flatten` to flatten the input image to the model.\n",
        "\n",
        " - Add 5 dense layers with `n_hidden` number of neurons and `selu` activation function.\n",
        "\n",
        " - Add a final dense layer with 8 neurons and `softmax` activation function(for classifying 8 classes of data).\n",
        "\n",
        "            model_A = keras.models.Sequential()\n",
        "            model_A.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
        "            for n_hidden in (300, 100, 50, 50, 50):\n",
        "                model_A.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
        "            model_A.add(keras.layers.Dense(8, activation=\"softmax\"))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEFpN2Np7vY-"
      },
      "source": [
        "# defining the model\n",
        "model_A = keras.models.Sequential()\n",
        "model_A.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
        "for n_hidden in (300, 100, 50, 50, 50):\n",
        "    model_A.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
        "model_A.add(keras.layers.Dense(8, activation=\"softmax\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJ9L2H0773-r"
      },
      "source": [
        "# compiling the model\n",
        "model_A.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                optimizer=keras.optimizers.SGD(lr=1e-3),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pD9acPB675xV",
        "outputId": "e729bc5d-c69b-44fe-fcd9-8dfb22e9e2d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# training the model\n",
        "history = model_A.fit(X_train_A, y_train_A, epochs=5,\n",
        "                    validation_data=(X_valid_A, y_valid_A))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "622/622 [==============================] - 2s 3ms/step - loss: 0.7979 - accuracy: 0.7498 - val_loss: 0.4762 - val_accuracy: 0.8490\n",
            "Epoch 2/5\n",
            "622/622 [==============================] - 2s 3ms/step - loss: 0.4260 - accuracy: 0.8582 - val_loss: 0.3921 - val_accuracy: 0.8652\n",
            "Epoch 3/5\n",
            "622/622 [==============================] - 2s 3ms/step - loss: 0.3702 - accuracy: 0.8736 - val_loss: 0.3701 - val_accuracy: 0.8714\n",
            "Epoch 4/5\n",
            "622/622 [==============================] - 2s 3ms/step - loss: 0.3418 - accuracy: 0.8811 - val_loss: 0.3284 - val_accuracy: 0.8879\n",
            "Epoch 5/5\n",
            "622/622 [==============================] - 2s 3ms/step - loss: 0.3240 - accuracy: 0.8870 - val_loss: 0.3230 - val_accuracy: 0.8876\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mp6Ajzgs77j7"
      },
      "source": [
        "model_A.save(\"my_model_A.h5\") # saving the model we created"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-6D_Ml-yOiL",
        "outputId": "f64d9dc2-863c-40c0-8339-37706f1d96c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "str(type(model_A))==\"<class 'tensorflow.python.keras.engine.sequential.Sequential'>\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DouFrqNu3jG"
      },
      "source": [
        "# Build and Fit the Model B\n",
        "\n",
        "- Let us define the model for the classification of data set B that we have created previously. \n",
        "\n",
        " Later, let us also examine the classification of B set by using the trained weights of model A.\n",
        "\n",
        " - We create a keras neural network as follows:\n",
        "\n",
        " - Add `keras.layers.Flatten` to flatten the input image to the model.\n",
        "\n",
        " - Add 5 dense layers with `n_hidden` number of neurons and `selu` activation function.\n",
        "\n",
        " - Add a final dense layer with 1 neuron and `softmax` activation function(for classifying 2 classes of data).\n",
        "\n",
        "            model_B = keras.models.Sequential()\n",
        "            model_B.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
        "            for n_hidden in (300, 100, 50, 50, 50):\n",
        "                model_B.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
        "            model_B.add(keras.layers.Dense(1, activation=\"softmax\"))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPFctmiU79g8"
      },
      "source": [
        "model_B = keras.models.Sequential()\n",
        "model_B.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
        "for n_hidden in (300, 100, 50, 50, 50):\n",
        "    model_B.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
        "model_B.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HanUIb4EvFRW"
      },
      "source": [
        "Setting `\"binary_crossentropy\"` as loss, as this is binary classification among sandals and shirts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTqeSYTe8AX4"
      },
      "source": [
        "\n",
        "# compiling the model with binary crossentropy\n",
        "# that can accept either logits (i.e values from last linear node, z)\n",
        "# or probabilities from the last Sigmoid node\n",
        "model_B.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=keras.optimizers.SGD(lr=1e-3),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZzAEM6n8DiB",
        "outputId": "77f7b600-ac51-42cd-a2ff-14c34b0446f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# training the model\n",
        "history = model_B.fit(X_train_B, y_train_B, epochs=5,\n",
        "                      validation_data=(X_valid_B, y_valid_B))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "161/161 [==============================] - 1s 5ms/step - loss: 0.2678 - accuracy: 0.9223 - val_loss: 0.1301 - val_accuracy: 0.9767\n",
            "Epoch 2/5\n",
            "161/161 [==============================] - 1s 3ms/step - loss: 0.0910 - accuracy: 0.9817 - val_loss: 0.0765 - val_accuracy: 0.9848\n",
            "Epoch 3/5\n",
            "161/161 [==============================] - 1s 3ms/step - loss: 0.0573 - accuracy: 0.9856 - val_loss: 0.0565 - val_accuracy: 0.9848\n",
            "Epoch 4/5\n",
            "161/161 [==============================] - 1s 3ms/step - loss: 0.0423 - accuracy: 0.9893 - val_loss: 0.0456 - val_accuracy: 0.9868\n",
            "Epoch 5/5\n",
            "161/161 [==============================] - 1s 3ms/step - loss: 0.0335 - accuracy: 0.9922 - val_loss: 0.0389 - val_accuracy: 0.9878\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pw3F6jqP8FXh",
        "outputId": "eed6026f-6b13-45fc-ad74-4bc76f2131b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_A.summary() # generating model summary"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 300)               235500    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               30100     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 8)                 408       \n",
            "=================================================================\n",
            "Total params: 276,158\n",
            "Trainable params: 276,158\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HhWzXny8HYf",
        "outputId": "0414d3e5-891c-44da-cfa4-4b79fd1ccf67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_B.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_1 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 300)               235500    \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 100)               30100     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 275,801\n",
            "Trainable params: 275,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pXQAu92vQ_6"
      },
      "source": [
        "# Creating new model based on existing model A\n",
        "\n",
        "- Let us first see how many trainable parameters are there for `model_B` we trained previously.\n",
        "\n",
        "- Then we shall create a new model `model_B_on_A` which has the pre-trained parameters of `model_A` but customized final dense layer with only 1 neuron.\n",
        "\n",
        "- Finally, we shall compare the performance of both the models - `model_B` and `model_B_on_A`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmfSOZcU8KLO"
      },
      "source": [
        "\n",
        "# model_A = keras.models.load_model(\"my_model_A.h5\") # loading our saved model\n",
        "model_B_on_A = keras.models.Sequential(model_A.layers[:-1]) # creating new model based on existing layer\n",
        "model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\")) # adding new layer to new model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfOo7OaTvXLE"
      },
      "source": [
        "\n",
        "- Now, before creating `model_B_on_A`(a model based on pre-trained layers of `model_A`), we shall clone the `model_A`  and set its trained weights so that when you train `model_B_on_A`, it will not affect `model_A`.\n",
        "\n",
        " We could copy the `model_A` architechture using `keras.models.clone_model`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0YyIUrd8Mp1"
      },
      "source": [
        "\n",
        "# model_A and model_B_on_A now share some layers. When you train\n",
        "# model_B_on_A, it will also affect model_A. To avoid that, you need to clone\n",
        "# model_A before you reuse its layers. To do this, you clone model A’s\n",
        "# architecture with clone_model(), then copy its weights\n",
        "# (since clone_model() does not clone the weights)\n",
        "model_A_clone = keras.models.clone_model(model_A)\n",
        "model_A_clone.set_weights(model_A.get_weights())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdbwQ_P68PdJ"
      },
      "source": [
        "# freezing reused layers\n",
        "for layer in model_B_on_A.layers[:-1]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# compiling the model\n",
        "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
        "                     optimizer=keras.optimizers.SGD(lr=1e-3),\n",
        "                     metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8LxZYr_ZxPd",
        "outputId": "cd10ed0d-19bc-4159-e3fc-43d61447396b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_B_on_A.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 300)               235500    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               30100     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 275,801\n",
            "Trainable params: 51\n",
            "Non-trainable params: 275,750\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ez5fOhDvvdGq"
      },
      "source": [
        " We observe there are only 51 parameters to train in `model_B_on_A`, while there are as many as 275,801 trainable parameters for `model_B`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIjVoJfl8R2E",
        "outputId": "d3f61760-f489-4df0-cf57-fd7a527d3108",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# training the model\n",
        "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=4,\n",
        "                           validation_data=(X_valid_B, y_valid_B))\n",
        "\n",
        "# unfreezing reused layers\n",
        "for layer in model_B_on_A.layers[:-1]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# compiling after reducing learning rate to avoid damaging the reused weights\n",
        "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
        "                     optimizer=keras.optimizers.SGD(lr=1e-3),\n",
        "                     metrics=[\"accuracy\"])\n",
        "\n",
        "# training the model\n",
        "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=5,\n",
        "                           validation_data=(X_valid_B, y_valid_B))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.9889 - accuracy: 0.5108 - val_loss: 0.3380 - val_accuracy: 0.9026\n",
            "Epoch 2/4\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.2137 - accuracy: 0.9580 - val_loss: 0.1554 - val_accuracy: 0.9736\n",
            "Epoch 3/4\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.1181 - accuracy: 0.9844 - val_loss: 0.1074 - val_accuracy: 0.9807\n",
            "Epoch 4/4\n",
            "161/161 [==============================] - 0s 2ms/step - loss: 0.0854 - accuracy: 0.9902 - val_loss: 0.0854 - val_accuracy: 0.9858\n",
            "Epoch 1/5\n",
            "161/161 [==============================] - 1s 4ms/step - loss: 0.0492 - accuracy: 0.9940 - val_loss: 0.0450 - val_accuracy: 0.9899\n",
            "Epoch 2/5\n",
            "161/161 [==============================] - 1s 3ms/step - loss: 0.0291 - accuracy: 0.9957 - val_loss: 0.0348 - val_accuracy: 0.9929\n",
            "Epoch 3/5\n",
            "161/161 [==============================] - 1s 3ms/step - loss: 0.0219 - accuracy: 0.9959 - val_loss: 0.0296 - val_accuracy: 0.9929\n",
            "Epoch 4/5\n",
            "161/161 [==============================] - 1s 3ms/step - loss: 0.0180 - accuracy: 0.9967 - val_loss: 0.0266 - val_accuracy: 0.9939\n",
            "Epoch 5/5\n",
            "161/161 [==============================] - 1s 3ms/step - loss: 0.0155 - accuracy: 0.9967 - val_loss: 0.0246 - val_accuracy: 0.9939\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Sx0hscQvlGk"
      },
      "source": [
        "# Evaluating the models\n",
        "\n",
        "- Now that we have the two models `model_B` and `model_B_on_A` for classifying the B dataset, let us evaluate the performance of the model based on their accuracies on the test data of B data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYXsAkyl8ThE",
        "outputId": "3d7044a9-8688-478c-c3b1-d3c85bec9e94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_B.evaluate(X_test_B, y_test_B) # evaluating the model A"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 0.9938\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.03187720850110054, 0.9937952160835266]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfmbvf2x8VTY",
        "outputId": "fa5da7a0-e1aa-49b1-c4f7-512d53f4d78c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_B_on_A.evaluate(X_test_B, y_test_B) # evaluating the model B"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0192 - accuracy: 0.9979\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.019171511754393578, 0.997931718826294]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v76OKjlMvrG2"
      },
      "source": [
        " We observe that the accuracies of both models are almost the same.\n",
        "\n",
        " We also see that the performance of `model_B_on_A` - with as less as 51 trainable parameter - stands to be as great as that of `model_B`with as many as 275,801.\n",
        "\n",
        " So, with very little training, `model_B_on_A` is performing really well. This saves time and resources even in real-time scenarios. This is the beauty of using pre-trained layers. This method is also known as transfer learning - transferring the knowledge obtained from solving one problem to solving another similar problem."
      ]
    }
  ]
}